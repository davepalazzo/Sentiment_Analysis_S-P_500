{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in as df of top 10 companies from 2007-2017 with MDA text\n",
    "df = pd.read_pickle('Top10_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "english_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message_sentence(msg):\n",
    "    '''Function takes in uncleaned MDA text. It removes all punctuation, exluding periods so the text can later be\n",
    "    analyized by sentence or words. And returns clean text in a list to be used for sentiment analysis.'''\n",
    "    \n",
    "    pattern = r'\\\\x[0-9]*|[^A-Za-z|\\.]+'\n",
    "    letters = ['x','k','s','ex','htm']\n",
    "    msg = str(msg).lower()\n",
    "    msg_tokens = nltk.word_tokenize(msg)\n",
    "    clean_msg_puct = ' '.join([re.sub(pattern,' ',w) for w in msg_tokens]).split()\n",
    "    clean_msg = [w for w in clean_msg_puct if w not in letters]\n",
    "    \n",
    "    return clean_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the df to clean MDA text for sentiment analysis\n",
    "for year in df:\n",
    "    for i in range(len(df)):\n",
    "        df1[year].iloc[i] = df1[year].iloc[i][0],clean_message_sentence(df1[year].iloc[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned MDA text for sentiment analysis\n",
    "df1.to_pickle('Cleaned_MDA_sentences.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectorizing Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(msg):\n",
    "    '''Function takes in uncleaned MDA text. It removes stop words, punctuation and digits, and lemmatize the word \n",
    "    token. It returns cleaned tecxt to me vectorized.'''\n",
    "        \n",
    "    pattern = r'\\\\x[0-9]*|[^A-Za-z]+'\n",
    "    letters = ['x','k','s','ex','htm']\n",
    "    msg = str(msg).lower()\n",
    "    msg_tokens = nltk.word_tokenize(msg)\n",
    "    clean_msg_tokens = [w for w in msg_tokens if w not in english_stopwords]\n",
    "    clean_msg_tokens_puct = ' '.join([re.sub(pattern,' ',w) for w in clean_msg_tokens ]).split()\n",
    "    clean_msg_tokens_letters = [w for w in clean_msg_tokens_puct if w not in letters]\n",
    "    lemmatized_token = [wordnet_lemmatizer.lemmatize(w) for w in  clean_msg_tokens_letters]\n",
    "    \n",
    "    return lemmatized_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the df to clean MDA text\n",
    "for year in df:\n",
    "    for i in range(len(df)):\n",
    "        df[year].iloc[i] = df[year].iloc[i][0],clean_message(df[year].iloc[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned MDA text w/o all punctuation\n",
    "df.to_pickle('Cleaned_MDA.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
