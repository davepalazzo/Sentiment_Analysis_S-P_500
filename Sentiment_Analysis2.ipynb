{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from cleanMDA import extractTable, divide_chunks, pullMDA, getXy\n",
    "from text_analysis import text_analysis_wordall, text_analysis_sentenceall, get_polarity, low_subjectivity, model_analysis\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis by Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company name and text in dataframe\n",
    "df_sentences = pd.read_pickle('Cleaned_MDA_sentences.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get GDP for 2007-2017 (import from GitHut)\n",
    "def get_GDP_visual(df):\n",
    "    USA = np.array(df[df['Data Source'] == 'United States'])\n",
    "\n",
    "    gdp_USA = pd.DataFrame(USA, columns=['Country Name', 'Country COde', 'Indicator Name', 'Indicator Code',\n",
    "                                                 '1960','1961','1962','1963','1964','1965','1966','1967','1968','1969',\n",
    "                                                 '1970','1971','1972','1973','1974','1975','1976','1977','1978','1979',\n",
    "                                                 '1980','1981','1982','1983','1984','1985','1986','1987','1988','1989',\n",
    "                                                 '1990','1991','1992','1993','1994','1995','1996','1997','1998','1999',\n",
    "                                                 '2000','2001','2002','2003','2004','2005','2006','2007','2008','2009',\n",
    "                                                 '2010','2011','2012','2013','2014','2015','2016','2017','2018'])\n",
    "\n",
    "    gdp_USA = gdp_USA.drop(columns=['Country Name','Country COde','Indicator Name','Indicator Code','1960','1961','1962',\n",
    "                                   '1963','1964','1965','1966','1967','1968','1969', '1970','1971','1972','1973','1974',\n",
    "                                   '1975','1976','1977','1978','1979', '1980','1981','1982','1983','1984','1985','1986',\n",
    "                                   '1987','1988','1989', '1990','1991','1992','1993','1994','1995','1996','1997','1998',\n",
    "                                   '1999', '2000','2001','2002','2003','2004','2005','2006','2018'])\n",
    "\n",
    "    gdp_USA_trans = gdp_USA.transpose()\n",
    "    gdp_USA_trans = gdp_USA_trans.rename(columns={0:'Y'})\n",
    "    \n",
    "    return gdp_USA_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = pd.read_csv('gdp_annual.csv')\n",
    "gdp_USA = get_GDP_visual(gdp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>[(frequently, 0.1, 0.3), (other, -0.125, 0.375...</td>\n",
       "      <td>1.77857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>[(frequently, 0.1, 0.3), (other, -0.125, 0.375...</td>\n",
       "      <td>-0.291621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>[(frequently, 0.1, 0.3), (other, -0.125, 0.375...</td>\n",
       "      <td>-2.77553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>[(frequently, 0.1, 0.3), (other, -0.125, 0.375...</td>\n",
       "      <td>2.53192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>[(frequently, 0.1, 0.3), (other, -0.125, 0.375...</td>\n",
       "      <td>1.60145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>[(other, -0.125, 0.375), (certain, 0.214285714...</td>\n",
       "      <td>2.22403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>[(other, -0.125, 0.375), (certain, 0.214285714...</td>\n",
       "      <td>1.67733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>[(other, -0.125, 0.375), (certain, 0.214285714...</td>\n",
       "      <td>2.56919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>[(other, -0.125, 0.375), (certain, 0.214285714...</td>\n",
       "      <td>2.86159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>[(other, -0.125, 0.375), (certain, 0.214285714...</td>\n",
       "      <td>1.48528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>[(other, -0.125, 0.375), (certain, 0.214285714...</td>\n",
       "      <td>2.27334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      X         y\n",
       "2007  [(frequently, 0.1, 0.3), (other, -0.125, 0.375...   1.77857\n",
       "2008  [(frequently, 0.1, 0.3), (other, -0.125, 0.375... -0.291621\n",
       "2009  [(frequently, 0.1, 0.3), (other, -0.125, 0.375...  -2.77553\n",
       "2010  [(frequently, 0.1, 0.3), (other, -0.125, 0.375...   2.53192\n",
       "2011  [(frequently, 0.1, 0.3), (other, -0.125, 0.375...   1.60145\n",
       "2012  [(other, -0.125, 0.375), (certain, 0.214285714...   2.22403\n",
       "2013  [(other, -0.125, 0.375), (certain, 0.214285714...   1.67733\n",
       "2014  [(other, -0.125, 0.375), (certain, 0.214285714...   2.56919\n",
       "2015  [(other, -0.125, 0.375), (certain, 0.214285714...   2.86159\n",
       "2016  [(other, -0.125, 0.375), (certain, 0.214285714...   1.48528\n",
       "2017  [(other, -0.125, 0.375), (certain, 0.214285714...   2.27334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the function text_analysis_wordall on the MDA text df\n",
    "analysis_df = text_analysis_wordall(df)\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_analysis_sentence(text, subjective=True):\n",
    "    pos = []\n",
    "    neg = []\n",
    "    # split for each sentence\n",
    "    for word in text.split(' . '):\n",
    "        blob = TextBlob(word)\n",
    "        sent = blob.sentiment\n",
    "        # eliminate words with high subjectivity\n",
    "#         if subjective:\n",
    "#             if sent.subjectivity < 0.7:\n",
    "#                 if sent.polarity > 0.25:\n",
    "#                     pos.append(sent.polarity)\n",
    "#                 elif sent.polarity < -0.25:\n",
    "#                     neg.append(sent.polarity)\n",
    "        \n",
    "    return word,sent.polarity,sent.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "## Sentiment Analysis by Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the company's text for each year and add the GDP of each year for sentence analysis\n",
    "df2 = getXy(df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function text_analysis_sentenceall on the MDA text df\n",
    "analysis_sentence = text_analysis_sentenceall(df2)\n",
    "analysis_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_sentence.to_pickle('sentence_analysis.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get just the polarity score from the sentence and word analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_word = pd.read_pickle('word_analysis.pkl')\n",
    "analysis_sentence = pd.read_pickle('sentence_analysis.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>[0.1, -0.125, -0.2, -0.05, -0.05, -0.125, -0.1...</td>\n",
       "      <td>1.77857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>[0.1, -0.125, -0.2, 0.7, -0.05, -0.05, -0.125,...</td>\n",
       "      <td>-0.291621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>[0.1, -0.125, -0.2, -0.05, -0.05, -0.125, -0.1...</td>\n",
       "      <td>-2.77553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>[0.1, -0.125, -0.2, -0.05, -0.05, -0.125, -0.1...</td>\n",
       "      <td>2.53192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>[0.1, -0.125, -0.2, -0.05, -0.05, -0.125, -0.1...</td>\n",
       "      <td>1.60145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>[-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...</td>\n",
       "      <td>2.22403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>[-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...</td>\n",
       "      <td>1.67733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>[-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...</td>\n",
       "      <td>2.56919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>[-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...</td>\n",
       "      <td>2.86159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>[-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...</td>\n",
       "      <td>1.48528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>[-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...</td>\n",
       "      <td>2.27334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      X         y\n",
       "2007  [0.1, -0.125, -0.2, -0.05, -0.05, -0.125, -0.1...   1.77857\n",
       "2008  [0.1, -0.125, -0.2, 0.7, -0.05, -0.05, -0.125,... -0.291621\n",
       "2009  [0.1, -0.125, -0.2, -0.05, -0.05, -0.125, -0.1...  -2.77553\n",
       "2010  [0.1, -0.125, -0.2, -0.05, -0.05, -0.125, -0.1...   2.53192\n",
       "2011  [0.1, -0.125, -0.2, -0.05, -0.05, -0.125, -0.1...   1.60145\n",
       "2012  [-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...   2.22403\n",
       "2013  [-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...   1.67733\n",
       "2014  [-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...   2.56919\n",
       "2015  [-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...   2.86159\n",
       "2016  [-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...   1.48528\n",
       "2017  [-0.125, 0.21428571428571427, 0.1, 0.375, -0.0...   2.27334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the function get_polarity on the word analysis df\n",
    "word_polarity = get_polarity(analysis_word)\n",
    "word_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>[-0.0140625, -0.05, -0.05, -0.125, -0.06666666...</td>\n",
       "      <td>1.77857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>[-0.011842105263157895, 0.7, -0.05, -0.05, -0....</td>\n",
       "      <td>-0.291621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>[-0.0140625, -0.05, -0.05, -0.125, -0.06666666...</td>\n",
       "      <td>-2.77553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>[-0.016071428571428573, -0.05, -0.05, -0.125, ...</td>\n",
       "      <td>2.53192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>[-0.013235294117647059, -0.05, -0.05, -0.125, ...</td>\n",
       "      <td>1.60145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>[-0.041666666666666664, 0.027380952380952377, ...</td>\n",
       "      <td>2.22403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>[-0.041666666666666664, 0.027380952380952377, ...</td>\n",
       "      <td>1.67733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>[-0.041666666666666664, 0.027380952380952377, ...</td>\n",
       "      <td>2.56919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>[-0.041666666666666664, 0.027380952380952377, ...</td>\n",
       "      <td>2.86159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>[-0.041666666666666664, 0.027380952380952377, ...</td>\n",
       "      <td>1.48528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>[-0.041666666666666664, 0.027380952380952377, ...</td>\n",
       "      <td>2.27334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      X         y\n",
       "2007  [-0.0140625, -0.05, -0.05, -0.125, -0.06666666...   1.77857\n",
       "2008  [-0.011842105263157895, 0.7, -0.05, -0.05, -0.... -0.291621\n",
       "2009  [-0.0140625, -0.05, -0.05, -0.125, -0.06666666...  -2.77553\n",
       "2010  [-0.016071428571428573, -0.05, -0.05, -0.125, ...   2.53192\n",
       "2011  [-0.013235294117647059, -0.05, -0.05, -0.125, ...   1.60145\n",
       "2012  [-0.041666666666666664, 0.027380952380952377, ...   2.22403\n",
       "2013  [-0.041666666666666664, 0.027380952380952377, ...   1.67733\n",
       "2014  [-0.041666666666666664, 0.027380952380952377, ...   2.56919\n",
       "2015  [-0.041666666666666664, 0.027380952380952377, ...   2.86159\n",
       "2016  [-0.041666666666666664, 0.027380952380952377, ...   1.48528\n",
       "2017  [-0.041666666666666664, 0.027380952380952377, ...   2.27334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the function get_polarity on the sentence analysis df\n",
    "sentence_polarity = get_polarity(analysis_sentence)\n",
    "sentence_polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:46:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:46:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# split Xs into individual columns and run analysis\n",
    "sentences_split_Xs = pd.DataFrame(sentence_polarity.X.tolist())\n",
    "sentence_split = model_analysis(np.array(sentences_split_Xs),np.array(sentence_polarity['y']))\n",
    "\n",
    "# get the sum of all the scores for each year and run analysis\n",
    "summed_sentence = np.array(sentence_polarity['X'].map(lambda x: sum(x)))\n",
    "Sum_sentence = model_analysis(summed_sentence,np.array(sentence_polarity['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3ed6dcc1e961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxgb_reg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# model learns from train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 458\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 570\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "models = [word_split,Sum_word,sentence_split,Sum_sentence]\n",
    "name = ['word_split','Sum_word','sentence_split','Sum_sentence']\n",
    "for i in range(len(models)):\n",
    "    print(name[i],models[i][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the best model from the code above we found was the Sum_word, we see if we can fit the model better by editing the parameters of subjectivity and polarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_analysis_word(df):\n",
    "    score = []\n",
    "    for word in text:\n",
    "        blob = TextBlob(word)\n",
    "        sent = blob.sentiment\n",
    "        # eliminate words with high subjectivity\n",
    "        if sent.subjectivity < 0.7:\n",
    "            if sent.polarity > 0.0:\n",
    "                score.append(sent.polarity)\n",
    "            elif sent.polarity < 0.0:\n",
    "                score.append(sent.polarity)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best parameters of the dataset for the model\n",
    "word_polarity_low = low_subjectivity(analysis_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# get the sum of all the scores for each year\n",
    "summed_word_low = np.array(word_polarity_low['X'].map(lambda x: sum(x)))\n",
    "Sum_word_best = model_analysis(summed_word_low,np.array(word_polarity_low['y']))\n",
    "print(Sum_word_best)\n",
    "print('Best score: ',Sum_word_best[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
